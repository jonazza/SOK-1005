---
title: "Data Science Project - SOK1005"
author: "Candidatenumber 5"
format: html
echo: true
output: true
warning: false
editor: visual
---

# Task 1 - Data Wrangling

```{r}
#cleaning enviroment and downloading required packages
rm(list = ls()) #clean enviroment

library(tidyverse) #tidyverse package
library(haven) #haven package
library(reshape2)
library(lubridate)
```

```{r}

#TASK 1

#customer count data
count <- read_dta("ccount.dta", encoding = "latin1")

#store-level demographic data
demo <- read_dta("demo.dta", encoding="latin1")

#cheese upc data
cheese_upc <- read.csv("https://www.chicagobooth.edu/-/media/enterprise/centers/kilts/datasets/dominicks-dataset/upc_csv-files/upcche.csv", encoding="latin1")

#cheese movement data
cheese_movement <- read.csv("wche.csv", encoding="latin1")

#merging upc and movement file.
cheese <- merge(cheese_upc,cheese_movement,by="UPC")
```

```{r}
#Manipulating cheese data

cheese <- cheese %>% mutate(SALES = (PRICE*MOVE)/QTY)
#Making date column for the weeks.

#date for start date of first week mentioned from the cheese movement data manual
start_date <- as.Date("1989-09-14")

#making date variable by using the start date of the first week and adding 7 days for every week passing by. 
cheese$DATE <- start_date + (cheese$WEEK - 1) * 7

#filter data only from 1990
cheese <- cheese %>% filter(DATE >= "1990-01-04" & DATE <= "1990-12-27") 

#resetting back to week 1 to represent the first week of 1990. 
cheese <- cheese %>% mutate(WEEK=WEEK-16)
```

```{r}
#manipulating count df

#removing rows with na data
count <- na.omit(count)

#removing store 0 and 1, since these barely contains any data.
count <- count %>% filter(store>=2)

#making the date var into date in r, to make it easier to work with. 
count$date <- as.Date(count$date, "%y%m%d")

#making date into same format as cheese df, to merge these together later
count$date <- format(count$date, "%Y-%m-%d")

#filtering dates from start dates.
count <- count %>% filter(date>=start_date)

#removing date column
count <- select(count, -date)

#group data by sotre and week and then summarizing all columns
count_weekly <- count %>%
  group_by(store, week) %>%
  summarise_all(list(sum = sum))

#rename columns to caps
count_weekly <- count_weekly %>% rename(STORE := store, WEEK := week)

#making date variable again, to make it same as the other df
count_weekly$DATE <- start_date + (count_weekly$WEEK - 1) * 7

#as.date
count_weekly$DATE <- as.Date(count_weekly$DATE)

#Filtering data for only 1990
count_weekly <- count_weekly %>% filter(DATE >= "1990-01-04" & DATE <= "1990-12-27")

#resetting week back to 1.
count_weekly <- count_weekly %>% mutate(WEEK = WEEK - 16)

#merging count weekly and cheese df
df<- merge(cheese, count_weekly, by = c("STORE", "WEEK", "DATE"))

#selecting data where move is > 0
df <- df %>% filter(MOVE>0)
```

```{r}
#define regular expressions to extract the brand names from the desc column
brand_regex <- c("KR ", "DOM ", "SARG ", "HH ", "BORDEN ")
brand_regex_pattern <- paste(brand_regex, collapse = "|")

#making a brand column. Brands not listen in brand_regex will show up as na.
df_2<- df %>%
  mutate(BRAND = str_extract(DESCRIP, brand_regex_pattern))

#removing na brands - aka brands we are not interested looking at
df_2 <- df_2 %>%
  filter(!is.na(BRAND))

#group by and merge data by brand and calculating some data needed.
df_2 <- df_2 %>%
  group_by(STORE, WEEK, DATE, BRAND) %>%
  summarise(SUM_SALES = sum(SALES),
            SUM_MOVE = sum(MOVE),
            AVG_PROFIT_MARGIN = mean(PROFIT),
            AVG_PRICE = mean(PRICE),
            CHEESE_SUM = sum(cheese_sum))
```

```{r}
#rename column
demo <- demo %>% rename(STORE := store)

#merging demo dataset to the rest
df_2_demo<- merge(df_2, demo, by = "STORE")

#selecting only first 25 colummns
df_2_demo <- df_2_demo[, 1:25]

#removing 2 unwanted columns
df_2_demo <- subset(df_2_demo, select = c(-name, -mmid, -weekvol, -scluster, -zone))

#writing df as csv
write_csv(df_2_demo, "df.csv")
```
